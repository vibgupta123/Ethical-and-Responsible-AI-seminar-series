# Ethical-and-Responsible-AI-seminar-series
Due to the proliferation of Artificial intelligence (AI) and machine learning (ML) nowadays, AI in healthcare
has made significant progress and have achieved human-level performance in skin cancer classification, diabetic
retinopathy detection, chest radiograph diagnosis, sepsis treatment, etc. While existing results are encouraging,
not too many clinical AI solutions are deployed in hospitals or actively utilized by physicians. A major problem is
that existing clinical AI methods are less trustworthy leading to misinformation, misdiagnosis, maltreatment, and disparities due to algorithmic and societal biases present in the development pipeline. For example, the existing methods are biased to specific ethnic groups which result in unfair predictions that are less reliable to other
ethnic groups. Moreover, existing approaches make clinical decisions in a black-box way, not robust to small
perturbations which raises security and privacy concerns. AI/ML algorithms not designed responsibly may
significantly increase the health disparities among underserved and minority community such as denied health
insurance and thus much needed healthcare due to racial bias and income inequality encoded in AI-algorithms
and data driven decision making.

We are seeking to provide trainings to investigators, staff, medical professionals, and graduate students regarding potential risks, opportunities and challenges for ethical and responsible AI in healthcare.

These trainings are supported by NSF Expand AI CAP award and RCMI supplement award 5U54MD007586-37S3 
